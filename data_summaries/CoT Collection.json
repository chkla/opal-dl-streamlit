{
    "cotcollection-en": {
        "Unique Dataset Identifier": "cotcollection-en",
        "Dataset Name": "cotcollection_en",
        "Collection": "CoT Collection",
        "Collection URL": "https://github.com/kaistAI/CoT-Collection",
        "Dataset URL": "https://github.com/kaistAI/CoT-Collection",
        "GitHub URL": "https://github.com/kaistAI/CoT-Collection",
        "Hugging Face URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection",
        "Paper Title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.14045",
        "Semantic Scholar Corpus ID": 258841149,
        "Languages": [
            "English"
        ],
        "Task Categories": [
            "Chain-of-Thought"
        ],
        "Text Domains": [],
        "Format": [
            "Chain-of-Thought"
        ],
        "Text Metrics": {
            "Num Dialogs": 1837928,
            "Mean Inputs Length": 793.0108,
            "Mean Targets Length": 283.4774,
            "Max Inputs Length": 34648,
            "Max Targets Length": 6802,
            "Min Inputs Length": 3,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [
            "OpenAI Codex"
        ],
        "Creators": [
            "KAIST",
            "Yonsei University",
            "NAVER AI Lab"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://github.com/kaistAI/CoT-Collection#license"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2305.14045"
            }
        ],
        "License Notes": "Uses OpenAI Codex model to generate rationales and ChatGPT to translate to other languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "en"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kaist-ai/CoT-Collection",
            "HF Config": "en",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "HF Downloads (June 2023)": 209,
            "HF Likes (June 2023)": 5,
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Citation Count (June 2023)": 1,
            "S2 Date": "2023-05-23",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "History",
                "Linguistics",
                "Science",
                "International relations",
                "Mathematics",
                "Sports",
                "Logic",
                "Climate change",
                "Travel"
            ]
        }
    },
    "cotcollection-fr": {
        "Unique Dataset Identifier": "cotcollection-fr",
        "Dataset Name": "cotcollection_fr",
        "Collection": "CoT Collection",
        "Collection URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Dataset URL": "https://github.com/kaistAI/CoT-Collection",
        "GitHub URL": "https://github.com/kaistAI/CoT-Collection",
        "Hugging Face URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Paper Title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.14045",
        "Semantic Scholar Corpus ID": 258841149,
        "Languages": [
            "French"
        ],
        "Task Categories": [
            "Chain-of-Thought"
        ],
        "Text Domains": [],
        "Format": [
            "Chain-of-Thought"
        ],
        "Text Metrics": {
            "Num Dialogs": 70400,
            "Mean Inputs Length": 668.903,
            "Mean Targets Length": 282.4849,
            "Max Inputs Length": 3749,
            "Max Targets Length": 3652,
            "Min Inputs Length": 6,
            "Min Targets Length": 3,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [
            "OpenAI Codex",
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "KAIST",
            "Yonsei University",
            "NAVER AI Lab"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://github.com/kaistAI/CoT-Collection#license"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2305.14045"
            }
        ],
        "License Notes": "Uses OpenAI Codex model to generate rationales and ChatGPT to translate to other languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "fr"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kaist-ai/CoT-Collection",
            "HF Config": "en",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "HF Downloads (June 2023)": 209,
            "HF Likes (June 2023)": 5,
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Citation Count (June 2023)": 1,
            "S2 Date": "2023-05-23",
            "GitHub License": "",
            "Text Topics": [
                "History",
                "Language learning",
                "Linguistics",
                "Language understanding",
                "Translation",
                "Geography",
                "Emotions",
                "Logic",
                "Politics",
                "Grammar"
            ]
        }
    },
    "cotcollection-ja": {
        "Unique Dataset Identifier": "cotcollection-ja",
        "Dataset Name": "cotcollection_ja",
        "Collection": "CoT Collection",
        "Collection URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Dataset URL": "https://github.com/kaistAI/CoT-Collection",
        "GitHub URL": "https://github.com/kaistAI/CoT-Collection",
        "Hugging Face URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Paper Title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.14045",
        "Semantic Scholar Corpus ID": 258841149,
        "Languages": [
            "Japanese"
        ],
        "Task Categories": [
            "Chain-of-Thought"
        ],
        "Text Domains": [],
        "Format": [
            "Chain-of-Thought"
        ],
        "Text Metrics": {
            "Num Dialogs": 65072,
            "Mean Inputs Length": 277.4443,
            "Mean Targets Length": 117.1297,
            "Max Inputs Length": 3254,
            "Max Targets Length": 1991,
            "Min Inputs Length": 2,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [
            "OpenAI Codex",
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "KAIST",
            "Yonsei University",
            "NAVER AI Lab"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://github.com/kaistAI/CoT-Collection#license"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2305.14045"
            }
        ],
        "License Notes": "Uses OpenAI Codex model to generate rationales and ChatGPT to translate to other languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "ja"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kaist-ai/CoT-Collection",
            "HF Config": "en",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "HF Downloads (June 2023)": 209,
            "HF Likes (June 2023)": 5,
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Citation Count (June 2023)": 1,
            "S2 Date": "2023-05-23",
            "GitHub License": "",
            "Text Topics": [
                "Travel",
                "Algorithms",
                "String manipulation",
                "History",
                "Science",
                "Translation",
                "Math",
                "Sports",
                "Linguistics",
                "Data analysis"
            ]
        }
    },
    "cotcollection-ko": {
        "Unique Dataset Identifier": "cotcollection-ko",
        "Dataset Name": "cotcollection_ko",
        "Collection": "CoT Collection",
        "Collection URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Dataset URL": "https://github.com/kaistAI/CoT-Collection",
        "GitHub URL": "https://github.com/kaistAI/CoT-Collection",
        "Hugging Face URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Paper Title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.14045",
        "Semantic Scholar Corpus ID": 258841149,
        "Languages": [
            "Korean"
        ],
        "Task Categories": [
            "Chain-of-Thought"
        ],
        "Text Domains": [],
        "Format": [
            "Chain-of-Thought"
        ],
        "Text Metrics": {
            "Num Dialogs": 77200,
            "Mean Inputs Length": 292.2117,
            "Mean Targets Length": 132.6346,
            "Max Inputs Length": 3196,
            "Max Targets Length": 1657,
            "Min Inputs Length": 2,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [
            "OpenAI Codex",
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "KAIST",
            "Yonsei University",
            "NAVER AI Lab"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://github.com/kaistAI/CoT-Collection#license"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2305.14045"
            }
        ],
        "License Notes": "Uses OpenAI Codex model to generate rationales and ChatGPT to translate to other languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "ko"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kaist-ai/CoT-Collection",
            "HF Config": "en",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "HF Downloads (June 2023)": 209,
            "HF Likes (June 2023)": 5,
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Citation Count (June 2023)": 1,
            "S2 Date": "2023-05-23",
            "GitHub License": "",
            "Text Topics": [
                "Geography",
                "Travel",
                "History",
                "Sports",
                "Biology",
                "Transportation",
                "Science",
                "Translation",
                "Chemistry",
                "Physics"
            ]
        }
    },
    "cotcollection-ru": {
        "Unique Dataset Identifier": "cotcollection-ru",
        "Dataset Name": "cotcollection_ru",
        "Collection": "CoT Collection",
        "Collection URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Dataset URL": "https://github.com/kaistAI/CoT-Collection",
        "GitHub URL": "https://github.com/kaistAI/CoT-Collection",
        "Hugging Face URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Paper Title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.14045",
        "Semantic Scholar Corpus ID": 258841149,
        "Languages": [
            "Russian"
        ],
        "Task Categories": [
            "Chain-of-Thought"
        ],
        "Text Domains": [],
        "Format": [
            "Chain-of-Thought"
        ],
        "Text Metrics": {
            "Num Dialogs": 60570,
            "Mean Inputs Length": 517.5606,
            "Mean Targets Length": 253.6704,
            "Max Inputs Length": 4078,
            "Max Targets Length": 4173,
            "Min Inputs Length": 7,
            "Min Targets Length": 2,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [
            "OpenAI Codex",
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "KAIST",
            "Yonsei University",
            "NAVER AI Lab"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://github.com/kaistAI/CoT-Collection#license"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2305.14045"
            }
        ],
        "License Notes": "Uses OpenAI Codex model to generate rationales and ChatGPT to translate to other languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "ru"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kaist-ai/CoT-Collection",
            "HF Config": "en",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "HF Downloads (June 2023)": 209,
            "HF Likes (June 2023)": 5,
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Citation Count (June 2023)": 1,
            "S2 Date": "2023-05-23",
            "GitHub License": "",
            "Text Topics": [
                "Translation",
                "Mathematics",
                "Geography",
                "Problem-solving",
                "Linguistics",
                "Language understanding",
                "Storytelling",
                "Language learning",
                "Math",
                "Arithmetic"
            ]
        }
    },
    "cotcollection-zh": {
        "Unique Dataset Identifier": "cotcollection-zh",
        "Dataset Name": "cotcollection_zh",
        "Collection": "CoT Collection",
        "Collection URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Dataset URL": "https://github.com/kaistAI/CoT-Collection",
        "GitHub URL": "https://github.com/kaistAI/CoT-Collection",
        "Hugging Face URL": "https://huggingface.co/datasets/kaist-ai/CoT-Collection_multilingual",
        "Paper Title": "The CoT Collection: Improving Zero-shot and Few-shot Learning of Language Models via Chain-of-Thought Fine-Tuning",
        "Papers with Code URL": "",
        "ArXiv URL": "https://arxiv.org/abs/2305.14045",
        "Semantic Scholar Corpus ID": 258841149,
        "Languages": [
            "Chinese"
        ],
        "Task Categories": [
            "Chain-of-Thought"
        ],
        "Text Domains": [],
        "Format": [
            "Chain-of-Thought"
        ],
        "Text Metrics": {
            "Num Dialogs": 71638,
            "Mean Inputs Length": 204.6967,
            "Mean Targets Length": 84.34,
            "Max Inputs Length": 2148,
            "Max Targets Length": 1570,
            "Min Inputs Length": 3,
            "Min Targets Length": 1,
            "Min Dialog Turns": 2,
            "Max Dialog Turns": 2,
            "Mean Dialog Turns": 2.0
        },
        "Text Sources": [],
        "Model Generated": [
            "OpenAI Codex",
            "OpenAI ChatGPT"
        ],
        "Creators": [
            "KAIST",
            "Yonsei University",
            "NAVER AI Lab"
        ],
        "Licenses": [
            {
                "License": "Non Commercial",
                "License URL": "https://github.com/kaistAI/CoT-Collection#license"
            },
            {
                "License": "OpenAI",
                "License URL": "https://arxiv.org/abs/2305.14045"
            }
        ],
        "License Notes": "Uses OpenAI Codex model to generate rationales and ChatGPT to translate to other languages",
        "License Verified By": "Shayne",
        "Dataset Filter IDs": [
            "zh"
        ],
        "Inferred Metadata": {
            "HF Dataset": "kaist-ai/CoT-Collection",
            "HF Config": "en",
            "HF Config License": "CC BY 4.0",
            "HF Yaml License": "",
            "HF Downloads (June 2023)": 209,
            "HF Likes (June 2023)": 5,
            "PwC License Name": "",
            "PwC License URL": "",
            "PwC Date": "",
            "S2 Citation Count (June 2023)": 1,
            "S2 Date": "2023-05-23",
            "GitHub License": "",
            "Text Topics": [
                "Math",
                "Geography",
                "Linguistics",
                "Sports",
                "Travel",
                "Logic",
                "Daily routine",
                "History",
                "Biology",
                "Translation"
            ]
        }
    }
}